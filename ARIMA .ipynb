{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49152a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import random\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79874084",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def inject_anomalies_ts(ts, \n",
    "                        types=['amplitude', 'trend', 'mean', 'platform', \n",
    "                               'pattern', 'pattern_shift', 'variance', \n",
    "                               'extremum', 'shift_30', 'shift_50'],\n",
    "                        inject_ratio=0.1, \n",
    "                        segment_length=7, \n",
    "                        seed=42):\n",
    "  \n",
    "    # Prepare data\n",
    "    if isinstance(ts, pd.Series):\n",
    "        idx = ts.index\n",
    "        data = ts.values.astype(float).copy()\n",
    "        return_series = True\n",
    "    else:\n",
    "        data = np.array(ts, dtype=float).copy()\n",
    "        idx = None\n",
    "        return_series = False\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "    n = len(data)\n",
    "    max_starts = n - segment_length + 1\n",
    "    n_segments = int(max_starts * inject_ratio)\n",
    "\n",
    "    # Select non-overlapping segment starts\n",
    "    candidates = list(range(max_starts))\n",
    "    random.shuffle(candidates)\n",
    "    chosen_starts = []\n",
    "    occupied = np.zeros(n, dtype=bool)\n",
    "    for start in candidates:\n",
    "        if not occupied[start:start+segment_length].any():\n",
    "            chosen_starts.append(start)\n",
    "            occupied[start:start+segment_length] = True\n",
    "            if len(chosen_starts) >= n_segments:\n",
    "                break\n",
    "\n",
    "    mask = np.zeros(n, dtype=bool)\n",
    "    labels = []\n",
    "\n",
    "    # Inject anomalies\n",
    "    for start in chosen_starts:\n",
    "        end = start + segment_length\n",
    "        window = data[start:end].copy()\n",
    "        anomaly_type = random.choice(types)\n",
    "\n",
    "        if anomaly_type == 'amplitude':\n",
    "            i = random.randint(0, segment_length-1)\n",
    "            window[i] += np.random.uniform(1.5, 3.0)\n",
    "        elif anomaly_type == 'extremum':\n",
    "            i = random.randint(0, segment_length-1)\n",
    "            window[i] = 1.0 if np.random.rand() > 0.5 else 0.0\n",
    "        elif anomaly_type == 'mean':\n",
    "            shift = np.random.uniform(0.3, 0.7)\n",
    "            window += shift\n",
    "        elif anomaly_type == 'trend':\n",
    "            trend = np.linspace(0, np.random.uniform(0.5, 1.0), segment_length)\n",
    "            window += trend\n",
    "        elif anomaly_type == 'platform':\n",
    "            mean_val = window.mean()\n",
    "            window[:] = mean_val\n",
    "        elif anomaly_type == 'pattern':\n",
    "            base = np.array([0.2, 0.4, 0.6, 0.4])\n",
    "            pat = np.tile(base, (segment_length//4 + 1,))[:segment_length]\n",
    "            window[:] = pat\n",
    "        elif anomaly_type == 'pattern_shift':\n",
    "            pat = np.sin(np.linspace(0, 2*np.pi, segment_length))\n",
    "            shift = random.randint(1, segment_length-1)\n",
    "            window[:] = np.roll(pat, shift)\n",
    "        elif anomaly_type == 'variance':\n",
    "            window += np.random.normal(0, 0.5, size=segment_length)\n",
    "        elif anomaly_type == 'shift_30':\n",
    "            factor = random.choice([0.3, -0.3])\n",
    "            window *= (1 + factor)\n",
    "        elif anomaly_type == 'shift_50':\n",
    "            factor = random.choice([0.5, -0.5])\n",
    "            window *= (1 + factor)\n",
    "\n",
    "        # Apply and clip\n",
    "        data[start:end] = np.clip(window, 0, 1)\n",
    "\n",
    "        # Mark mask & labels\n",
    "        if anomaly_type in ('amplitude', 'extremum'):\n",
    "            anomaly_idx = start + i\n",
    "            mask[anomaly_idx] = True\n",
    "            labels.append((anomaly_idx, anomaly_idx+1, anomaly_type))\n",
    "        else:\n",
    "            mask[start:end] = True\n",
    "            labels.append((start, end, anomaly_type))\n",
    "\n",
    "    # Return in original format\n",
    "    if return_series:\n",
    "        ts_mod = pd.Series(data, index=idx, name=ts.name)\n",
    "    else:\n",
    "        ts_mod = data\n",
    "\n",
    "    return ts_mod, mask, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c4cac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Loop through each dataset in new_dict\n",
    "for filename, df_selected in new_dict.items():\n",
    "    print(f\"Processing {filename}...\")\n",
    "\n",
    "    # Ensure datetime index\n",
    "    df_selected.index = pd.to_datetime(df_selected.index)\n",
    "\n",
    "    # Define rolling window parameters\n",
    "    train_window = pd.Timedelta(days=60)  \n",
    "    predict_horizon = pd.Timedelta(days=1) \n",
    "\n",
    "    # Initialize lists to store results\n",
    "    arima_params = []\n",
    "    aics = []\n",
    "    bics = []\n",
    "    errors = []\n",
    "    mses = []\n",
    "    predictions_list = []\n",
    "    actual_values_list = []\n",
    "    dates = []\n",
    "\n",
    "\n",
    "    date_start = df_selected.index.min()\n",
    "    date_end = df_selected.index.max()\n",
    "    current_start = date_start\n",
    "    iteration = 1\n",
    "\n",
    "    while current_start + train_window + predict_horizon <= date_end:\n",
    "        # Define training and prediction windows\n",
    "        train_end = current_start + train_window - predict_horizon \n",
    "        predict_start = train_end + predict_horizon \n",
    "\n",
    "        print(f\"Iteration {iteration}: Training from {current_start.date()} to {train_end.date()}, Predicting {predict_start.date()}\")\n",
    "\n",
    "        train_data = df_selected.loc[current_start:train_end]\n",
    "        test_data = df_selected.loc[predict_start:predict_start]\n",
    "\n",
    "        # Fit Auto ARIMA\n",
    "        model = auto_arima(train_data,\n",
    "                           seasonal=False,\n",
    "                           d=None,\n",
    "                           start_p=0, max_p=10,\n",
    "                           start_q=0, max_q=10,\n",
    "                           max_order= None,\n",
    "                           max_d=2,\n",
    "                           trace=True,\n",
    "                           n_jobs=10,\n",
    "                           error_action=\"ignore\",\n",
    "                           suppress_warnings=True,\n",
    "                           stepwise=False)\n",
    "\n",
    "        # Make predictions\n",
    "        forecast = model.predict(n_periods=1)\n",
    "\n",
    "        # Compute error metrics\n",
    "        mae = mean_absolute_error(test_data, forecast)\n",
    "        mse = mean_squared_error(test_data, forecast)\n",
    "\n",
    "        # Store results\n",
    "        arima_params.append(model.order)\n",
    "        aics.append(model.aic())\n",
    "        bics.append(model.bic())\n",
    "        errors.append(mae)\n",
    "        mses.append(mse)\n",
    "        predictions_list.append(forecast[0])\n",
    "        actual_values_list.append(test_data.iloc[0])\n",
    "        dates.append(predict_start.date())\n",
    "\n",
    "        # Move the window forward by one day\n",
    "        current_start += predict_horizon\n",
    "        iteration += 1\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        \"Date\": dates,\n",
    "        \"ARIMA_Params\": arima_params,\n",
    "        \"AIC\": aics,\n",
    "        \"BIC\": bics,\n",
    "        \"MAE\": errors,\n",
    "        \"MSE\": mses,\n",
    "        \"Forecast\": predictions_list,\n",
    "        \"Actual Values\": actual_values_list\n",
    "    })\n",
    "\n",
    "    # Save results to CSV\n",
    "    csv_filename = f\"{filename.replace('.csv', '')}_arima_injected_results.csv\"\n",
    "    results_df.to_csv(csv_filename, index=False)\n",
    "    print(f\"Results saved to {csv_filename}\\n\")\n",
    "\n",
    "print(\"Processing complete for all datasets.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
